{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=datasets.MNIST('data/MNIST_data/', train=True, download=True,\n",
    "                     transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test=datasets.MNIST('data/MNIST_data/',\n",
    "                    train=False,\n",
    "                    download=True,\n",
    "                    transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([60000])\n",
      "784 10\n"
     ]
    }
   ],
   "source": [
    "x=train.data.float()/255\n",
    "y=train.targets\n",
    "\n",
    "x=x.view(x.size(0), -1)\n",
    "print(x.size(), y.size())\n",
    "\n",
    "input_size=x.size(-1)\n",
    "output_size=int(max(y))+1\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48000, 12000]\n"
     ]
    }
   ],
   "source": [
    "ratios=[0.8, 0.2]\n",
    "train_cnt = int(x.size(0) * ratios[0])\n",
    "valid_cnt = int(x.size(0) * ratios[1])\n",
    "test_cnt=len(test.data)\n",
    "cnts=[train_cnt, valid_cnt]\n",
    "print(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10621, 43798, 56664,  ...,  8893, 54656, 56144])\n"
     ]
    }
   ],
   "source": [
    "indices=torch.randperm(x.size(0))\n",
    "print(indices)\n",
    "x=torch.index_select(x, dim=0, index=indices)\n",
    "y=torch.index_select(y, dim=0, index=indices)\n",
    "\n",
    "x=list(x.split(cnts, dim=0))\n",
    "y=list(y.split(cnts, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000]) torch.Size([12000])\n"
     ]
    }
   ],
   "source": [
    "print(y[0].size(), y[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 784]) torch.Size([48000])\n",
      "torch.Size([12000, 784]) torch.Size([12000])\n",
      "torch.Size([10000, 784]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "x+=[(test.data.float()/255).view(test_cnt, -1)]\n",
    "y+=[test.targets]\n",
    "\n",
    "for x_i, y_i in zip(x, y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 use_batch_norm=True,\n",
    "                 dropout_p=0.4):\n",
    "        self.input_size=input_size\n",
    "        self.output_size=output_size\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p=dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        def get_regulaizer(use_batch_norm, size):\n",
    "            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.block=nn.Sequential(\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.LeakyReLU(),\n",
    "            get_regulaizer(use_batch_norm, output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y=self.block(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, use_batch_norm=True, dropout_p=0.4 ) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers=nn.Sequential(\n",
    "            Block(input_size, 500, use_batch_norm, dropout_p),\n",
    "            Block(500, 400, use_batch_norm, dropout_p),\n",
    "            Block(400, 300, use_batch_norm, dropout_p),\n",
    "            Block(300, 200, use_batch_norm, dropout_p),\n",
    "            Block(200, 100, use_batch_norm, dropout_p),\n",
    "            nn.Linear(100, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        y= self.layers(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyModel(input_size, output_size, use_batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)\n",
    "x=[x_i.to(device) for x_i in x]\n",
    "y=[y_i.to(device) for y_i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "n_epochs=10000\n",
    "batch_size=256\n",
    "print_interval=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lowest_loss=np.inf\n",
    "best_model=None\n",
    "early_stop=100\n",
    "lowest_epoch=np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "Epoch :  10 train loss :  0.004153110943826369 valid_loss :  0.018450313059604793 lowest_loss :  0.016080166508800176\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "Epoch :  20 train loss :  0.0015353965182026861 valid_loss :  0.016761628923372233 lowest_loss :  0.016080166508800176\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 0 : 0.000000e+00\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "Epoch :  30 train loss :  0.0007496975482654113 valid_loss :  0.0158498275626958 lowest_loss :  0.015828107672340202\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 21 : 2.100000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "Epoch :  40 train loss :  0.0018180638511539461 valid_loss :  0.017313140118598573 lowest_loss :  0.015600676879281699\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "Epoch :  50 train loss :  0.00019569352279167436 valid_loss :  0.016383841994346376 lowest_loss :  0.015600676879281699\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 34 : 3.400000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "Epoch :  60 train loss :  0.000991182722634434 valid_loss :  0.017376611483281783 lowest_loss :  0.015445670265307854\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "Epoch :  70 train loss :  0.0006731791607288617 valid_loss :  0.016597670752422085 lowest_loss :  0.015445670265307854\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "Epoch :  80 train loss :  0.0009799880542396614 valid_loss :  0.01695643380129955 lowest_loss :  0.015445670265307854\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "Epoch :  90 train loss :  0.0013420699821057149 valid_loss :  0.01848916334282486 lowest_loss :  0.015445670265307854\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "Epoch :  100 train loss :  0.001461805651313219 valid_loss :  0.016417861903911608 lowest_loss :  0.015445670265307854\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "Epoch :  110 train loss :  0.002675171922458097 valid_loss :  0.017300588862553923 lowest_loss :  0.015445670265307854\n",
      "best validation loss from epoch 56 : 5.600000e+01\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  120 train loss :  6.931900011803474e-05 valid_loss :  0.016491553809828474 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  130 train loss :  0.00024499123408754423 valid_loss :  0.017544896628221198 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  140 train loss :  0.00010868517820997712 valid_loss :  0.016548867933514493 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  150 train loss :  0.00031559306306133564 valid_loss :  0.01556782599514658 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  160 train loss :  0.0016642588160953272 valid_loss :  0.018190009694600513 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  170 train loss :  0.00024824202732864426 valid_loss :  0.018111684900369646 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  180 train loss :  0.003022788710798019 valid_loss :  0.01847887972274163 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  190 train loss :  0.00039653316456862855 valid_loss :  0.015527011420065915 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  200 train loss :  0.0016927886864320809 valid_loss :  0.022668759886983025 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "Epoch :  210 train loss :  0.000341745059617619 valid_loss :  0.016507537694191603 lowest_loss :  0.01530265490808753\n",
      "best validation loss from epoch 110 : 1.100000e+02\n",
      "There is no improvement duraing last 100 epoch\n"
     ]
    }
   ],
   "source": [
    "train_history, valid_history = [], []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    model.train()\n",
    "    indices=torch.randperm(x[0].size(0)).to(device)\n",
    "    x_=torch.index_select(x[0], dim=0, index=indices)\n",
    "    y_=torch.index_select(y[0], dim=0, index=indices)\n",
    "    x_=x_.split(batch_size, dim=0)\n",
    "    y_=y_.split(batch_size, dim=0)\n",
    "\n",
    "    train_loss, valid_loss=0,0\n",
    "\n",
    "    y_hat = []\n",
    "\n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i = model(x_i)\n",
    "        loss=crit(y_hat_i, y_i.squeeze())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=float(loss)\n",
    "\n",
    "    train_loss=train_loss/len(x_)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_=x[1].split(batch_size, dim=0)\n",
    "        y_=y[1].split(batch_size, dim=0)\n",
    "\n",
    "        valid_loss=0\n",
    "\n",
    "        for x_i, y_i in zip(x_, y_):\n",
    "            y_hat_i=model(x_i)\n",
    "            loss=crit(y_hat_i, y_i.squeeze())\n",
    "\n",
    "            valid_loss+=float(loss)\n",
    "            y_hat += [y_hat_i]\n",
    "\n",
    "    valid_loss=valid_loss/len(x_i)\n",
    "\n",
    "    train_history+=[train_loss]\n",
    "    valid_history+=[valid_loss]\n",
    "\n",
    "    if(i+1) % print_interval==0: \n",
    "        print('Epoch : ',(i+1), 'train loss : ',train_loss, 'valid_loss : ', valid_loss, 'lowest_loss : ', lowest_loss)\n",
    "\n",
    "    if valid_loss <= lowest_loss :\n",
    "        lowest_loss = valid_loss\n",
    "        lowest_epoch=i\n",
    "\n",
    "        best_model=deepcopy(model.state_dict())\n",
    "    else:\n",
    "        if early_stop > 0 and lowest_epoch + early_stop < i+1:\n",
    "            print(\"There is no improvement duraing last %d epoch\"%early_stop)\n",
    "            break\n",
    "    print(\"best validation loss from epoch %d : %4e\" %(lowest_epoch, lowest_epoch))\n",
    "\n",
    "    model.load_state_dict(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
