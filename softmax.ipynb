{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "z=torch.FloatTensor([1,2,3])\n",
    "y_hat=F.softmax(z, dim=0)\n",
    "print(y_hat)\n",
    "print(y_hat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1509, 0.1093, 0.2410, 0.2325, 0.2663],\n",
      "        [0.1198, 0.2818, 0.2303, 0.2154, 0.1527],\n",
      "        [0.1451, 0.1991, 0.2654, 0.1724, 0.2180]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z=torch.rand(3,5, requires_grad=True)\n",
    "y_hat=F.softmax(z, dim=1)\n",
    "print(y_hat)\n",
    "\n",
    "print(y_hat.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 3])\n",
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.randint(5, (3,)).long()\n",
    "print(y)\n",
    "y_one_hot=torch.zeros_like(y_hat)\n",
    "y_one_hot.scatter_(1,y.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3],\n",
      "        [4],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "print(y.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x213c9efa1b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_data=[[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]]\n",
    "y_data=[2,2,2,1,1,1,0,0]\n",
    "x_train=torch.FloatTensor(x_data)\n",
    "y_train=torch.LongTensor(y_data)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot=torch.zeros(8,3)\n",
    "y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.zeros((4,3), requires_grad=True)\n",
    "b=torch.zeros((1,3), requires_grad=True)\n",
    "optimizer=optim.SGD([W, b], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0 Cost :  1.0986123085021973\n",
      "Epoch :  100 Cost :  0.7041996121406555\n",
      "Epoch :  200 Cost :  0.6229995489120483\n",
      "Epoch :  300 Cost :  0.5657169222831726\n",
      "Epoch :  400 Cost :  0.5152913331985474\n",
      "Epoch :  500 Cost :  0.467661589384079\n",
      "Epoch :  600 Cost :  0.4212779700756073\n",
      "Epoch :  700 Cost :  0.37540146708488464\n",
      "Epoch :  800 Cost :  0.3297656178474426\n",
      "Epoch :  900 Cost :  0.2850724160671234\n",
      "Epoch :  1000 Cost :  0.24815461039543152\n",
      "Epoch :  1100 Cost :  0.23267605900764465\n",
      "Epoch :  1200 Cost :  0.22139872610569\n",
      "Epoch :  1300 Cost :  0.2111290991306305\n",
      "Epoch :  1400 Cost :  0.2017364501953125\n",
      "Epoch :  1500 Cost :  0.19311320781707764\n",
      "Epoch :  1600 Cost :  0.18516962230205536\n",
      "Epoch :  1700 Cost :  0.177829310297966\n",
      "Epoch :  1800 Cost :  0.17102722823619843\n",
      "Epoch :  1900 Cost :  0.16470743715763092\n",
      "Epoch :  2000 Cost :  0.1588211953639984\n",
      "Epoch :  2100 Cost :  0.15332652628421783\n",
      "Epoch :  2200 Cost :  0.14818623661994934\n",
      "Epoch :  2300 Cost :  0.1433679759502411\n",
      "Epoch :  2400 Cost :  0.13884282112121582\n",
      "Epoch :  2500 Cost :  0.13458563387393951\n",
      "Epoch :  2600 Cost :  0.1305735558271408\n",
      "Epoch :  2700 Cost :  0.126786470413208\n",
      "Epoch :  2800 Cost :  0.12320637702941895\n",
      "Epoch :  2900 Cost :  0.11981715261936188\n",
      "Epoch :  3000 Cost :  0.1166040301322937\n",
      "Epoch :  3100 Cost :  0.11355400085449219\n",
      "Epoch :  3200 Cost :  0.11065523326396942\n",
      "Epoch :  3300 Cost :  0.10789673775434494\n",
      "Epoch :  3400 Cost :  0.10526889562606812\n",
      "Epoch :  3500 Cost :  0.10276288539171219\n",
      "Epoch :  3600 Cost :  0.1003703624010086\n",
      "Epoch :  3700 Cost :  0.09808401763439178\n",
      "Epoch :  3800 Cost :  0.09589691460132599\n",
      "Epoch :  3900 Cost :  0.09380307793617249\n",
      "Epoch :  4000 Cost :  0.09179650992155075\n",
      "Epoch :  4100 Cost :  0.08987216651439667\n",
      "Epoch :  4200 Cost :  0.0880250483751297\n",
      "Epoch :  4300 Cost :  0.08625070005655289\n",
      "Epoch :  4400 Cost :  0.08454480022192001\n",
      "Epoch :  4500 Cost :  0.08290372043848038\n",
      "Epoch :  4600 Cost :  0.08132388442754745\n",
      "Epoch :  4700 Cost :  0.07980190217494965\n",
      "Epoch :  4800 Cost :  0.07833455502986908\n",
      "Epoch :  4900 Cost :  0.07691936194896698\n",
      "Epoch :  5000 Cost :  0.07555314153432846\n",
      "Epoch :  5100 Cost :  0.07423388212919235\n",
      "Epoch :  5200 Cost :  0.07295890152454376\n",
      "Epoch :  5300 Cost :  0.07172627747058868\n",
      "Epoch :  5400 Cost :  0.07053367048501968\n",
      "Epoch :  5500 Cost :  0.06937956809997559\n",
      "Epoch :  5600 Cost :  0.06826180964708328\n",
      "Epoch :  5700 Cost :  0.06717897951602936\n",
      "Epoch :  5800 Cost :  0.06612923741340637\n",
      "Epoch :  5900 Cost :  0.06511133909225464\n",
      "Epoch :  6000 Cost :  0.06412373483181\n",
      "Epoch :  6100 Cost :  0.06316520273685455\n",
      "Epoch :  6200 Cost :  0.062234364449977875\n",
      "Epoch :  6300 Cost :  0.06133011728525162\n",
      "Epoch :  6400 Cost :  0.06045139208436012\n",
      "Epoch :  6500 Cost :  0.059597041457891464\n",
      "Epoch :  6600 Cost :  0.05876612663269043\n",
      "Epoch :  6700 Cost :  0.05795775726437569\n",
      "Epoch :  6800 Cost :  0.05717095732688904\n",
      "Epoch :  6900 Cost :  0.05640485882759094\n",
      "Epoch :  7000 Cost :  0.05565883219242096\n",
      "Epoch :  7100 Cost :  0.0549318864941597\n",
      "Epoch :  7200 Cost :  0.05422351509332657\n",
      "Epoch :  7300 Cost :  0.053532786667346954\n",
      "Epoch :  7400 Cost :  0.05285930633544922\n",
      "Epoch :  7500 Cost :  0.05220220237970352\n",
      "Epoch :  7600 Cost :  0.051561079919338226\n",
      "Epoch :  7700 Cost :  0.050935324281454086\n",
      "Epoch :  7800 Cost :  0.05032433569431305\n",
      "Epoch :  7900 Cost :  0.04972760006785393\n",
      "Epoch :  8000 Cost :  0.04914465919137001\n",
      "Epoch :  8100 Cost :  0.04857514053583145\n",
      "Epoch :  8200 Cost :  0.04801830276846886\n",
      "Epoch :  8300 Cost :  0.047474123537540436\n",
      "Epoch :  8400 Cost :  0.04694186896085739\n",
      "Epoch :  8500 Cost :  0.04642133414745331\n",
      "Epoch :  8600 Cost :  0.0459119938313961\n",
      "Epoch :  8700 Cost :  0.045413628220558167\n",
      "Epoch :  8800 Cost :  0.04492580145597458\n",
      "Epoch :  8900 Cost :  0.04444821923971176\n",
      "Epoch :  9000 Cost :  0.04398063197731972\n",
      "Epoch :  9100 Cost :  0.04352262616157532\n",
      "Epoch :  9200 Cost :  0.043073881417512894\n",
      "Epoch :  9300 Cost :  0.04263424873352051\n",
      "Epoch :  9400 Cost :  0.042203307151794434\n",
      "Epoch :  9500 Cost :  0.041780974715948105\n",
      "Epoch :  9600 Cost :  0.041366904973983765\n",
      "Epoch :  9700 Cost :  0.040960900485515594\n",
      "Epoch :  9800 Cost :  0.040562596172094345\n",
      "Epoch :  9900 Cost :  0.04017191380262375\n"
     ]
    }
   ],
   "source": [
    "n_epochs=10000\n",
    "for epoch in range(n_epochs):\n",
    "    y_hat=F.softmax(x_train.matmul(W)+b, dim=1)\n",
    "    cost=(y_one_hot * -torch.log(y_hat)).sum(dim=1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch : ',epoch, 'Cost : ', cost.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
